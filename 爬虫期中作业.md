# 爬虫期中作业

------

## 	爬虫程序



### 		豆瓣电影top

> ```python
> from lxml import etree
> import requests
> import MySQLdb
> 
> def get_movies(i):
>  #设置请求头
>  headers={
>  'user-agent':'Mozilla/5.0 (Windows NT 6.1;Win64;x64) AppleWebKit/537.36 (KHTML,like Gecko) Chrome/52.0.2743.82 Safari/537.36',
>  'Host':'movie.douban.com'
>          }
>  movie_list=[]
>  for a in range(i):
>      link='https://movie.douban.com/top250?start='+ str(a*25)
>      r=requests.get(link,headers=headers)
>      s = etree.HTML(r.text)
>      All_movie = s.xpath('//*[@id="content"]/div/div[1]/ol/li')
>      for Movie in All_movie:
>          conn=MySQLdb.connect(host='localhost',
>                                  user='dxj',
>                                  passwd='a81877568',
>                                  db='oa',
>                                  charset='utf8')
>          cur=conn.cursor()
>          M_name=Movie.xpath('./div/div[2]/div[1]/a/span[1]/text()')
>          name=",".join(map(str, M_name))
>          M_star=Movie.xpath('./div/div[2]/div[2]/div/span[2]/text()')
>          star=",".join(map(str, M_star))
>          M_href=Movie.xpath('./div/div[2]/div[1]/a/@href')
>          href=",".join(map(str, M_href))
>          #将数据插入相应的电影表中
>          sql="INSERT INTO top_movie(m_name,m_star,m_href) VALUES ('%s','%s','%s')"%(name,star,href)
>          movie_list.append(M_name)
>          cur.execute(sql)
>          cur.close()
>          conn.commit()
>          conn.close()
>  #返回电影列表
>  return movie_list
> if __name__ == "__main__":
>  movies=get_movies(4)
>  print (movies)
> ```
>
> **所遇到问题：**
>
> 1. xpath返回的内容为list
>
>    所以我尝试用代码将其转为字符串，如：
>
> ```python
> M_name=Movie.xpath('./div/div[2]/div[1]/a/span[1]/text()')
>          name=",".join(map(str, M_name))
> ```
>
> ​	2.

### 		



### 		京东手机

> ```python
> import requests
> from lxml import etree
> import time
> import MySQLdb
> #定义函数抓取每页前60条商品信息
> def get_mobile(n):
>  #构造每一页的url变化
>  url='https://search.jd.com/Search?keyword=%E6%89%8B%E6%9C%BA&enc=utf-8&qrst=1&rt=1&stop=1&vt=2&cid2=653&cid3=655&page='+str(2*n-1)
>  headers = {'authority': 'search.jd.com',
>          'method': 'GET',
>          'scheme': 'https',
>          'referer': 'https://search.jd.com/Search?keyword=%E6%89%8B%E6%9C%BA&enc=utf-8&qrst=1&rt=1&stop=1&vt=2&wq=%E6%89%8B%E6%9C%BA&cid2=653&cid3=655&page=1&s=58&click=0',
>          'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36',
>          'x-requested-with': 'XMLHttpRequest',
>          'Cookie':'qrsc=3; pinId=RAGa4xMoVrs; xtest=1210.cf6b6759; ipLocation=%u5E7F%u4E1C; _jrda=5; TrackID=1aUdbc9HHS2MdEzabuYEyED1iDJaLWwBAfGBfyIHJZCLWKfWaB_KHKIMX9Vj9_2wUakxuSLAO9AFtB2U0SsAD-mXIh5rIfuDiSHSNhZcsJvg; shshshfpa=17943c91-d534-104f-a035-6e1719740bb6-1525571955; shshshfpb=2f200f7c5265e4af999b95b20d90e6618559f7251020a80ea1aee61500; cn=0; 3AB9D23F7A4B3C9B=QFOFIDQSIC7TZDQ7U4RPNYNFQN7S26SFCQQGTC3YU5UZQJZUBNPEXMX7O3R7SIRBTTJ72AXC4S3IJ46ESBLTNHD37U; ipLoc-djd=19-1607-3638-3638.608841570; __jdu=930036140; user-key=31a7628c-a9b2-44b0-8147-f10a9e597d6f; areaId=19; __jdv=122270672|direct|-|none|-|1529893590075; PCSYCityID=25; mt_xid=V2_52007VwsQU1xaVVoaSClUA2YLEAdbWk5YSk9MQAA0BBZOVQ0ADwNLGlUAZwQXVQpaAlkvShhcDHsCFU5eXENaGkIZWg5nAyJQbVhiWR9BGlUNZwoWYl1dVF0%3D; __jdc=122270672; shshshfp=72ec41b59960ea9a26956307465948f6; rkv=V0700; __jda=122270672.930036140.-.1529979524.1529984840.85; __jdb=122270672.1.930036140|85.1529984840; shshshsID=f797fbad20f4e576e9c30d1c381ecbb1_1_1529984840145'
>          }
>  r = requests.get(url, headers=headers)
>  #指定编码方式，不然会出现乱码
>  r.encoding='utf-8'
>  htmltext = etree.HTML(r.text)
>  #定位到每一个商品标签li
>  datas=htmltext.xpath('//li[contains(@class,"gl-item")]')
>  #将数据存储到mysql数据库
>  mobile_list=[]
>  for data in datas:
>      conn=MySQLdb.connect(host='localhost',
>                               user='dxj',
>                               passwd='a81877568',
>                               db='python',
>                               charset='utf8')
>      cur=conn.cursor()
>      array_price =data.xpath('./div/div[3]/strong/i/text()[1]')
>      p_price = ",".join(map(str, array_price))
>      array_comment =data.xpath('./div/div[4]/a/i/text()')
>      p_comment = ",".join(map(str, array_comment))
>      array_name = data.xpath('./div/div[4]/a/em/text()')
>      p_name = ",".join(map(str, array_name))
>      mobile_list.append(p_name)
>      sql="INSERT INTO jd_mobile(m_name,m_price,m_comment) VALUES('%s','%s','%s')"%(p_name,p_price,p_comment)
>      cur.execute(sql)
>      cur.close()
>      conn.commit()
>      conn.close()
>  return mobile_list
> #定义函数抓取每页后30条商品信息
> 
> def get_last(n):
>  #获取当前的Unix时间戳，并且保留小数点后5位
>  a=time.time()
>  b='%.5f'%a
>  url='https://search.jd.com/s_new.php?keyword=%E6%89%8B%E6%9C%BA&enc=utf-8&qrst=1&rt=1&stop=1&vt=2&wq=%E6%89%8B%E6%9C%BA&cid2=653&cid3=655&page='+str(2*n)+'&s='+str(48*n-20)+'&scrolling=y&log_id='+str(b)
>  head={'authority': 'search.jd.com',
>          'method': 'GET',
>          'path': '/s_new.php?keyword=%E6%89%8B%E6%9C%BA&enc=utf-8&qrst=1&rt=1&stop=1&vt=2&wq=%E6%89%8B%E6%9C%BA&cid2=653&cid3=655&page=4&s=84&scrolling=y&log_id=1529828108.22071&tpl=3_M&show_items=7651927,7367120,7056868,7419252,6001239,5934182,4554969,3893501,7421462,6577495,26480543553,7345757,4483120,6176077,6932795,7336429,5963066,5283387,25722468892,7425622,4768461',
>          'scheme': 'https',
>          'referer': 'https://search.jd.com/Search?keyword=%E6%89%8B%E6%9C%BA&enc=utf-8&qrst=1&rt=1&stop=1&vt=2&wq=%E6%89%8B%E6%9C%BA&cid2=653&cid3=655&page=3&s=58&click=0',
>          'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36',
>          'x-requested-with': 'XMLHttpRequest',
>          'Cookie':'qrsc=3; pinId=RAGa4xMoVrs; xtest=1210.cf6b6759; ipLocation=%u5E7F%u4E1C; _jrda=5; TrackID=1aUdbc9HHS2MdEzabuYEyED1iDJaLWwBAfGBfyIHJZCLWKfWaB_KHKIMX9Vj9_2wUakxuSLAO9AFtB2U0SsAD-mXIh5rIfuDiSHSNhZcsJvg; shshshfpa=17943c91-d534-104f-a035-6e1719740bb6-1525571955; shshshfpb=2f200f7c5265e4af999b95b20d90e6618559f7251020a80ea1aee61500; cn=0; 3AB9D23F7A4B3C9B=QFOFIDQSIC7TZDQ7U4RPNYNFQN7S26SFCQQGTC3YU5UZQJZUBNPEXMX7O3R7SIRBTTJ72AXC4S3IJ46ESBLTNHD37U; ipLoc-djd=19-1607-3638-3638.608841570; __jdu=930036140; user-key=31a7628c-a9b2-44b0-8147-f10a9e597d6f; areaId=19; __jdv=122270672|direct|-|none|-|1529893590075; PCSYCityID=25; mt_xid=V2_52007VwsQU1xaVVoaSClUA2YLEAdbWk5YSk9MQAA0BBZOVQ0ADwNLGlUAZwQXVQpaAlkvShhcDHsCFU5eXENaGkIZWg5nAyJQbVhiWR9BGlUNZwoWYl1dVF0%3D; __jdc=122270672; shshshfp=72ec41b59960ea9a26956307465948f6; rkv=V0700; __jda=122270672.930036140.-.1529979524.1529984840.85; __jdb=122270672.1.930036140|85.1529984840; shshshsID=f797fbad20f4e576e9c30d1c381ecbb1_1_1529984840145'
>          }
>  r = requests.get(url, headers=head)
>  r.encoding = 'utf-8'
>  html1 = etree.HTML(r.text)
>  datas = html1.xpath('//li[contains(@class,"gl-item")]')
>  #将数据存储到mysql数据库
>  mobile_list2=[]
>  for data in datas:
>      conn=MySQLdb.connect(host='localhost',
>                               user='dxj',
>                               passwd='a81877568',
>                               db='python',
>                               charset='utf8')
>      cur=conn.cursor()
>      array_price =data.xpath('./div/div[3]/strong/i/text()[1]')
>      p_price = ",".join(map(str, array_price))
>      array_comment =data.xpath('./div/div[4]/a/i/text()')
>      p_comment = ",".join(map(str, array_comment))
>      array_name = data.xpath('./div/div[4]/a/em/text()')
>      p_name = ",".join(map(str, array_name))
>      mobile_list2.append(p_name)
>      sql="INSERT INTO jd_mobile(m_name,m_price,m_comment) VALUES('%s','%s','%s')"%(p_name,p_price,p_comment)
>      cur.execute(sql)
>      cur.close()
>      conn.commit()
>      conn.close()
>  return mobile_list2
> 
> if __name__=='__main__':
>  for i in range(1,2):
>      #下面的print函数主要是为了方便查看当前抓到第几页了
>      print('***************************************************')
>      try:
>          print('   First_Page:   ' + str(i))
>          mobile_list1=get_mobile(i)
>          mobile_list2=get_last(i)
>          print('   Finish')
>          print(mobile_list1)
>          print(mobile_list2)
>      except Exception as e:
>          print(e)
>      print('------------------')
> ```
>
> **部分借鉴了网上的内容**
>
> 前三十条是直接显示，所以可以直接爬取，后三十为动态加载通过找到对应的API接口，然后构造请求来模拟浏览器。





## 	Django



### 		搭建环境

> **进入venv环境**
>
> 创建对应Django文件夹，在对应文件夹下输入命令
>
> > *1.创建虚拟环境*
> >
> > python -m venv venv
> >
> > *2.运行文件*
> >
> > venv/Scripts/activate.bat
> >
> > 进入如下图所示界面
> >
> > ![1556169266106](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\1556169266106.png)
>
> **安装相应库**
>
> > *1.更新包管理工具pip*
> >
> > ```
> > (venv) C:\Users\asus\Desktop\Django>python -m pip install --upgrade pip
> > ```
> >
> > *2.下载Django与PyMysql*
> >
> > ```
> > pip install django==2.0
> > pip install PyMysql
> > ```
> >
> > 下载的版本是Django2.0与PyMysql0.9.3
> >
> > 可通过pip list查看对应版本





### 		构建项目与管理

#### 			创建项目

> ```
> django-admin startproject Pyspider
> ```
>
> 创建动态页面
>
> ```
> python manage.py startapp Spider
> ```
>
> **连接mysql数据库**
>
> *打开settings文件*
>
> ```python
> #将Spider添加已安装的项目中
> INSTALLED_APPS = [
>  'django.contrib.admin',
>  'django.contrib.auth',
>  'django.contrib.contenttypes',
>  'django.contrib.sessions',
>  'django.contrib.messages',
>  'django.contrib.staticfiles',
>  'Spider'，
> ]
> '''省略'''
> #修改连接内容
> DATABASES = {
>  'default': {
>      'ENGINE': 'django.db.backends.mysql',
>      #已创建好的数据库
>      'NAME': 'oa',
>      'HOST': 'localhost',
>      'PORT': 3306,
>      'USER': 'dxj',
>      'PASSWORD': 'a81877568',
>  }
> }
> ```
>
> 修改**项目**的`__init__.py`文件并加入如下所示的代码，这段代码的作用是将PyMySQL视为MySQLdb来使用，从而避免Django找不到连接MySQL的客户端工具而询问你：“Did you install mysqlclient? ”
>
> ```python
> import pymysql
> 
> pymysql.install_as_MySQLdb()
> ```
>
> 尝试使用python manage.py migrate实现数据库迁移，为应用程序创建对应的数据表
>
> 发生报错
>
> ```
> django.db.utils.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '; SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED' at line 1")
> ```
>
> 查询资料发现可能与我mysql版本有关
>
> 在DATABASES中添加了一句'OPTIONS':{'isolation_level':None} 运行成功
>
> ![1556171830350](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\1556171830350.png)

#### 			初次运行

> ```
> python manage.py runserver
> #运行后进入http://127.0.0.1:8000/
> ```
>
> ![1556172022723](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\1556172022723.png)



#### 			后台管理模型

> 1.  建立超级用户
>
> ```
> python manage.py createsuperuser
> ```
>
> ![1556172266245](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\1556172266245.png)
>
> 观察数据库发现用户创建成功并且密码加密了
>
> 2. 登录后台管理系统
>
> 样式原先无法显示
>
> ![1556175114481](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\1556175114481.png)
>
> 查询大量资料，尝试数遍后发现修改base.html的<!DOCTYPE html>标签就可以正常显示
>
> ![1556175058623](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\1556175058623.png)
>
>    3. 创建models
>
>    先尝试豆瓣电影top250
>
>    编写models文件
>
>    ```python
>    from django.db import models
>    
>    # Create your models here.
>    class Movie(models.Model):
>        #列的内容
>        Movie_name = models.CharField(max_length=255, db_column='m_name', verbose_name='电影名称')
>        class Meta:
>            db_table = 'top_movie'
>    ```
>
>    通过模型创建数据表。
>
>    ```
>    python manage.py makemigrations Spider
>    python manage.py migrate
>    ```
>
>    ![1556176238736](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\1556176238736.png)
>
>    运行完毕发现创建成功



####   			注册模型类

>    ```python
>    from django.contrib import admin
>    
>    from Spider.models import Movie
>    
>    admin.site.register(Movie)		
>    ```
>
>    ![1556176399114](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\1556176399114.png)
>
> ​	进行测试
>
> ![1556185563334](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\1556185563334.png)
>
> ![1556185580620](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\1556185580620.png)

#### 			管理界面优化

> ​	
>
> ```python
> from django.contrib import admin
> 
> from Spider.models import Movie
> 
> class MovieAdmin(admin.ModelAdmin):
>     list_display = ('id','Movie_name')
>     search_fields = ('id','Movie_name')
> 
> admin.site.register(Movie,MovieAdmin)
> 
> ```
>
> ![1556186340784](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\1556186340784.png)

## 	页面设计

### 		修改views.py

​      		 **以豆瓣为例 **

> ```python
> #coding:utf-8
> from django.shortcuts import render
> from Spider.models import Movie
> # Create your views here.
> def show_movie(request):
>     ctx = {'movie_list': Movie.objects.all()}
>     return render(request, 'demo/movie.html', ctx)
> ```

### 		修改urls.py

> *为模板页增加路径*
>
> ```python
> from django.contrib import admin
> from django.urls import path
> 
> from Spider import views
> urlpatterns = [
>     
>     path('admin/', admin.site.urls),
>     path('movie/', views.show_movie),
> ]
> ```

### 		设计模板页

> <html lang="en">
> <head>
>     <meta http-equiv="Content-Type" content="text/html; charset="UTF-8"/>
>     <title>豆瓣电影</title>
>     <style>
>         body {
>             width: 960px;
>             margin: 0 auto;
>         }
>         .mov {
>             margin: 20px 10px;
>         }
>     </style>
> </head>
> <body>
>     <h1>豆瓣电影</h1>
>     <hr>
>     {% for movie in movie_list %}
> 	<h2>{{movie.Movie_name }}</h2>
>     <dl class="mov">
>         <dt>{{movie.Movie_star}}</dt>
>         <dd>{{movie.Movie_href}}</dd>
>     </dl>
>     {% endfor %}
> </body>
> </html>

### 		结果展示

> ![1556245937815](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\1556245937815.png)

## 	

## 	最终结果

### 		豆瓣

> 结果之前已经差不多展示了就不再展示

### 		京东

> 京东手机内容爬取与豆瓣大体类似
>
> *在已有环境下流程*
>
> ![1556275729945](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\1556275729945.png)
>
> 
>
> *结果如下*
>
> ![1556278320161](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\1556278320161.png)

## 总结感想

> ​	在做的途中可以说大小bug不断，各种版本不兼容问题等等，所幸的是最终还是完成了。虽然说最后的展示并不好看，也没有做什么花里胡哨的东西，但是总的过程还是大致上了解了。毕竟这还只是初步的内容，后期会逐步完善 ，如：
>
> > 1. 爬取图片进行保存
> > 2. 将爬虫程序写入Django框架中，而不是独立出去
> > 3. 为每条内容添加链接，转入详细介绍的页面
> > 4. 融入Ajax内容对电影手机进行评价
> > 5. 实现“用户注册”和“用户登录”的功能。
> > 6. 尝试使用多线程爬取网页
>
> 还算任重道远，仍需努力，不过目前就到此为止吧~
>
> OVER~